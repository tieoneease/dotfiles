#!/usr/bin/env python3

"""
Voice-to-text recorder daemon with live waveform popup.

Runs as a persistent daemon (started at login via systemd).
On SIGUSR1: toggles between recording and idle.
Records audio, transcribes via whisper-cli, types the result with dotoolc.

State machine (all transitions on GLib main thread):
  IDLE ─SIGUSR1→ RECORDING ─SIGUSR1→ TRANSCRIBING ─done→ TYPING ─done→ IDLE
"""

import collections
import json
import math
import os
import signal
import subprocess
import time
import threading
import wave

import numpy as np
import sounddevice as sd

import gi
gi.require_version("Gtk", "4.0")
gi.require_version("Gtk4LayerShell", "1.0")
from gi.repository import Gtk, Gdk, GLib, Gtk4LayerShell

PID_FILE = "/tmp/voice-recorder.pid"
WHISPER_MODEL = os.path.expanduser("~/.local/share/whisper-models/ggml-base.en.bin")
SAMPLE_RATE = 16000
CHANNELS = 1
NUM_BARS = 32
SMOOTHING = 0.55
WAV_FILE = "/tmp/voice-recording.wav"
COLORS_FILE = os.path.expanduser("~/.config/noctalia/colors.json")

# Pre-generate ready chime: ascending two-note (C5→E5) with harmonics
CHIME_DURATION = 0.28
CHIME_SAMPLES = int(SAMPLE_RATE * CHIME_DURATION)
_t = np.linspace(0, CHIME_DURATION, CHIME_SAMPLES, endpoint=False, dtype=np.float32)

# Exponential decay envelope with soft 5ms attack
_attack = np.minimum(_t / 0.005, 1.0)
_decay_tau = 0.08

# Note 1: C5 (523 Hz) starts at t=0
_env1 = _attack * np.exp(-_t / _decay_tau)
_note1 = _env1 * (np.sin(2 * np.pi * 523 * _t) + 0.3 * np.sin(2 * np.pi * 1046 * _t) + 0.1 * np.sin(2 * np.pi * 1569 * _t))

# Note 2: E5 (659 Hz) starts at t=80ms
_t2_offset = 0.08
_mask2 = (_t >= _t2_offset).astype(np.float32)
_t2_shifted = np.maximum(_t - _t2_offset, 0.0)
_env2 = np.minimum(_t2_shifted / 0.005, 1.0) * np.exp(-_t2_shifted / _decay_tau) * _mask2
_note2 = _env2 * (np.sin(2 * np.pi * 659 * _t) + 0.3 * np.sin(2 * np.pi * 1318 * _t) + 0.1 * np.sin(2 * np.pi * 1977 * _t))

READY_TONE = (0.25 * (_note1 + _note2)).astype(np.float32)

# Pre-compute chime RMS envelope for waveform injection (~64ms windows matching UI timer)
_chime_window_ms = 64
_chime_window_samples = int(SAMPLE_RATE * _chime_window_ms / 1000)
CHIME_RMS_ENVELOPE = []
for _i in range(0, CHIME_SAMPLES, _chime_window_samples):
    _chunk = READY_TONE[_i:_i + _chime_window_samples]
    CHIME_RMS_ENVELOPE.append(float(np.sqrt(np.mean(_chunk ** 2))))

del _t, _attack, _decay_tau, _env1, _note1, _t2_offset, _mask2, _t2_shifted, _env2, _note2
del _chime_window_ms, _chime_window_samples, _i, _chunk

# States
IDLE = "idle"
RECORDING = "recording"
TRANSCRIBING = "transcribing"
TYPING = "typing"


# --- Colors ---

def hex_to_rgb(hex_color):
    """Convert '#rrggbb' to (r, g, b) floats 0.0–1.0."""
    h = hex_color.lstrip("#")
    return (int(h[0:2], 16) / 255.0, int(h[2:4], 16) / 255.0, int(h[4:6], 16) / 255.0)


def load_colors():
    """Load theme colors from noctalia colors.json, with fallbacks."""
    defaults = {
        "surface": "#121316",
        "on_surface_variant": "#c3c6cf",
        "primary": "#9fcaff",
    }
    try:
        with open(COLORS_FILE) as f:
            data = json.load(f)
        defaults["surface"] = data.get("mSurface", defaults["surface"])
        defaults["on_surface_variant"] = data.get("mOnSurfaceVariant", defaults["on_surface_variant"])
        defaults["primary"] = data.get("mPrimary", defaults["primary"])
    except (FileNotFoundError, json.JSONDecodeError, KeyError):
        pass

    defaults["primary_rgb"] = hex_to_rgb(defaults["primary"])
    defaults["on_surface_variant_rgb"] = hex_to_rgb(defaults["on_surface_variant"])
    return defaults


# --- Daemon State ---

class RecorderDaemon:
    def __init__(self):
        self.state = IDLE
        self.app = None
        self.colors = None

        # Per-session state (reset between recordings)
        self.audio_chunks = []
        self.rms_history = collections.deque([0.0] * NUM_BARS, maxlen=NUM_BARS)
        self.smooth_bars = [0.0] * NUM_BARS
        self.start_time = 0.0
        self.transcribed_text = None
        self.stream = None

        # UI widgets (created/destroyed per session)
        self.window = None
        self.drawing_area = None
        self.rec_dot = None
        self.label_time = None
        self.ui_timer_id = None
        self.css_provider = None

    def reset_session(self):
        """Clear per-session state between recordings."""
        self.audio_chunks = []
        self.rms_history = collections.deque([0.0] * NUM_BARS, maxlen=NUM_BARS)
        self.smooth_bars = [0.0] * NUM_BARS
        self.start_time = 0.0
        self.transcribed_text = None

    # --- Chime waveform injection ---

    def inject_chime_waveform(self):
        """Feed pre-computed chime RMS into rms_history for visual burst."""
        self._chime_idx = 0

        def _inject_step():
            if self._chime_idx >= len(CHIME_RMS_ENVELOPE):
                return False  # done
            chime_rms = CHIME_RMS_ENVELOPE[self._chime_idx] * 3.0
            # Blend: chime wins unless mic is louder
            current = self.rms_history[-1] if self.rms_history else 0.0
            self.rms_history.append(max(current, chime_rms))
            self._chime_idx += 1
            return self._chime_idx < len(CHIME_RMS_ENVELOPE)

        GLib.timeout_add(64, _inject_step)

    # --- Audio ---

    def audio_callback(self, indata, frames, time_info, status):
        """Called by sounddevice for each audio block."""
        self.audio_chunks.append(indata.copy())
        rms = float(np.sqrt(np.mean(indata ** 2)))
        self.rms_history.append(rms)

    def save_wav(self):
        """Save recorded audio chunks to WAV file."""
        if not self.audio_chunks:
            return False
        audio = np.concatenate(self.audio_chunks, axis=0)
        audio_int16 = np.clip(audio * 32767, -32768, 32767).astype(np.int16)
        with wave.open(WAV_FILE, "w") as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes(audio_int16.tobytes())
        return True

    # --- Transcription ---

    def transcribe(self):
        """Run whisper-cli transcription, return text."""
        try:
            result = subprocess.run(
                ["whisper-cli", "-m", WHISPER_MODEL, "-f", WAV_FILE, "-np", "-nt"],
                capture_output=True, text=True, timeout=120
            )
            text = result.stdout.strip()
            lines = []
            for line in text.splitlines():
                line = line.strip()
                if not line or line == "[BLANK_AUDIO]":
                    continue
                lines.append(line)
            return " ".join(lines).strip()
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            notify(f"Transcription failed: {e}")
            return ""

    # --- State transitions ---

    def start_recording(self):
        """IDLE → RECORDING: reload colors, open stream, build window, play tone."""
        if self.state != IDLE:
            return

        # Reload colors in case wallpaper changed
        self.colors = load_colors()
        self.reset_session()
        self.start_time = time.monotonic()

        # Open audio stream
        try:
            self.stream = sd.InputStream(
                samplerate=SAMPLE_RATE,
                channels=CHANNELS,
                dtype="float32",
                blocksize=1024,
                callback=self.audio_callback,
            )
            self.stream.start()
        except Exception as e:
            self.stream = None
            notify(f"Audio device error: {e}")
            return  # stay IDLE, don't crash

        self.state = RECORDING

        # Build UI
        self.build_window()

        # Play ready chime (non-blocking, uses output device — won't be captured by input)
        try:
            sd.play(READY_TONE, samplerate=SAMPLE_RATE)
        except Exception:
            pass  # no output device? no problem, just skip the chime

        # Inject chime energy into waveform for initial visual burst
        self.inject_chime_waveform()

        # Start UI refresh timer (~30fps)
        self.ui_timer_id = GLib.timeout_add(33, self.update_ui)

    def stop_recording(self):
        """RECORDING → TRANSCRIBING: stop stream, save WAV, spawn transcription."""
        if self.state != RECORDING:
            return

        self.state = TRANSCRIBING

        # Stop audio stream
        if self.stream is not None:
            self.stream.stop()
            self.stream.close()
            self.stream = None

        # Save audio, then transcribe in a thread to keep UI responsive
        if self.save_wav():
            t = threading.Thread(target=self._transcribe_then_type, daemon=True)
            t.start()
        else:
            notify("No audio recorded")
            self._teardown_to_idle()

    def _transcribe_then_type(self):
        """Run transcription (blocking), then schedule typing on main thread."""
        self.transcribed_text = self.transcribe()
        GLib.idle_add(self._finish_transcription)

    def _finish_transcription(self):
        """TRANSCRIBING → TYPING: destroy window, schedule typing."""
        if self.state != TRANSCRIBING:
            return False  # cancelled by Escape
        self._destroy_window()

        if not self.transcribed_text:
            self.state = IDLE
            return False

        self.state = TYPING
        # Brief delay to let compositor settle focus after overlay teardown
        GLib.timeout_add(300, self._type_text)
        return False

    def _type_text(self):
        """Type transcribed text, then return to IDLE."""
        text = self.transcribed_text
        try:
            result = subprocess.run(
                ["dotoolc"], input=f"type {text}\n",
                text=True, timeout=10
            )
            if result.returncode != 0:
                raise RuntimeError("dotoolc failed")
        except (subprocess.TimeoutExpired, FileNotFoundError, RuntimeError):
            # dotoolc unavailable — fall back to clipboard
            try:
                subprocess.run(["wl-copy", "--", text], timeout=5)
                notify("Transcription copied to clipboard (dotool unavailable)")
            except (subprocess.TimeoutExpired, FileNotFoundError):
                notify("Could not type or copy transcription")

        self.state = IDLE
        return False  # don't repeat timer

    def _teardown_to_idle(self):
        """Clean up and return to IDLE from any state."""
        if self.stream is not None:
            try:
                self.stream.stop()
                self.stream.close()
            except Exception:
                pass
            self.stream = None
        self._destroy_window()
        self.state = IDLE

    def _destroy_window(self):
        """Destroy the overlay window and clean up UI state."""
        if self.ui_timer_id is not None:
            GLib.source_remove(self.ui_timer_id)
            self.ui_timer_id = None
        if self.css_provider is not None:
            Gtk.StyleContext.remove_provider_for_display(
                Gdk.Display.get_default(), self.css_provider
            )
            self.css_provider = None
        if self.window is not None:
            self.window.destroy()
            self.window = None
        self.drawing_area = None
        self.rec_dot = None
        self.label_time = None

    # --- Key handler ---

    def on_key_pressed(self, controller, keyval, keycode, state):
        """Escape cancels recording or transcription."""
        if keyval == Gdk.KEY_Escape and self.state in (RECORDING, TRANSCRIBING):
            self._teardown_to_idle()
            return True
        return False

    # --- Signal handlers ---

    def on_sigusr1(self):
        """Handle SIGUSR1: toggle between IDLE and RECORDING."""
        if self.state == IDLE:
            self.start_recording()
        elif self.state == RECORDING:
            self.stop_recording()
        # TRANSCRIBING / TYPING → ignore
        return True  # keep signal handler registered

    def on_sigterm(self):
        """Handle SIGTERM: clean shutdown."""
        self._teardown_to_idle()
        # Remove PID file
        try:
            os.unlink(PID_FILE)
        except FileNotFoundError:
            pass
        if self.app is not None:
            self.app.quit()
        return False

    # --- UI ---

    def draw_waveform(self, area, cr, width, height):
        """Draw mirrored waveform bars with glow and exponential smoothing."""
        gap = 2
        bar_width = max(1, (width - (NUM_BARS - 1) * gap) / NUM_BARS)
        max_rms = 0.08
        center_y = height / 2
        max_half = (height / 2) - 2

        bars = list(self.rms_history)

        r_active, g_active, b_active = self.colors["primary_rgb"]
        r_muted, g_muted, b_muted = self.colors["on_surface_variant_rgb"]

        PI = 3.14159

        elapsed = time.monotonic() - self.start_time

        for i, rms in enumerate(bars):
            x = i * (bar_width + gap)

            if self.state == TRANSCRIBING:
                # Traveling sine wave: sweeps left-to-right across bars
                wave = math.sin(elapsed * 2.5 - i * 0.35)
                wave_norm = 0.5 + 0.5 * wave  # 0.0–1.0
                half_h = max_half * (0.15 + 0.15 * wave_norm)
                alpha = 0.25 + 0.15 * wave_norm
                cr.set_source_rgba(r_active, g_active, b_active, alpha)
            else:
                target = min(rms / max_rms, 1.0)
                self.smooth_bars[i] += SMOOTHING * (target - self.smooth_bars[i])
                normalized = self.smooth_bars[i] ** 0.45
                half_h = max(2, normalized * max_half)

            y = center_y - half_h
            bar_h = half_h * 2
            radius = min(bar_width / 2, 3)

            if self.state != TRANSCRIBING:
                # Glow layer: expanded, semi-transparent
                glow_expand = 1.5
                glow_half = half_h * glow_expand
                glow_y = center_y - glow_half
                glow_h = glow_half * 2
                glow_x = x - (bar_width * (glow_expand - 1) / 2)
                glow_w = bar_width * glow_expand
                glow_r = min(glow_w / 2, 4)
                cr.set_source_rgba(r_active, g_active, b_active, 0.15 * normalized)
                cr.new_sub_path()
                cr.arc(glow_x + glow_w - glow_r, glow_y + glow_r, glow_r, -0.5 * PI, 0)
                cr.arc(glow_x + glow_w - glow_r, glow_y + glow_h - glow_r, glow_r, 0, 0.5 * PI)
                cr.arc(glow_x + glow_r, glow_y + glow_h - glow_r, glow_r, 0.5 * PI, PI)
                cr.arc(glow_x + glow_r, glow_y + glow_r, glow_r, PI, 1.5 * PI)
                cr.close_path()
                cr.fill()

                # Crisp bar
                cr.set_source_rgba(r_active, g_active, b_active, 0.5 + 0.5 * normalized)

            cr.new_sub_path()
            cr.arc(x + bar_width - radius, y + radius, radius, -0.5 * PI, 0)
            cr.arc(x + bar_width - radius, y + bar_h - radius, radius, 0, 0.5 * PI)
            cr.arc(x + radius, y + bar_h - radius, radius, 0.5 * PI, PI)
            cr.arc(x + radius, y + radius, radius, PI, 1.5 * PI)
            cr.close_path()
            cr.fill()

    def update_ui(self):
        """Periodic UI update (~30fps)."""
        if self.window is None or not self.window.get_visible():
            return False

        elapsed = time.monotonic() - self.start_time

        if self.state == TRANSCRIBING:
            ndots = int(elapsed * 2) % 3 + 1
            self.label_time.set_text("Transcribing" + "." * ndots + " " * (3 - ndots))
            if self.rec_dot.has_css_class("rec-dot"):
                self.rec_dot.remove_css_class("rec-dot")
                self.rec_dot.add_css_class("transcribing-dot")
            opacity = 0.65 + 0.15 * math.sin(elapsed * math.pi)
            self.rec_dot.set_opacity(opacity)
        else:
            minutes = int(elapsed) // 60
            seconds = int(elapsed) % 60
            self.label_time.set_text(f"{minutes}:{seconds:02d}")
            opacity = 0.7 + 0.3 * (0.5 + 0.5 * math.sin(elapsed * 2 * math.pi))
            self.rec_dot.set_opacity(opacity)

        self.drawing_area.queue_draw()
        return True

    def build_window(self):
        """Build the GTK4 layer-shell popup window — compact pill."""
        window = Gtk.ApplicationWindow(application=self.app)
        self.window = window

        # Layer shell setup
        Gtk4LayerShell.init_for_window(window)
        Gtk4LayerShell.set_layer(window, Gtk4LayerShell.Layer.OVERLAY)
        Gtk4LayerShell.set_keyboard_mode(window, Gtk4LayerShell.KeyboardMode.ON_DEMAND)
        Gtk4LayerShell.set_anchor(window, Gtk4LayerShell.Edge.BOTTOM, True)
        Gtk4LayerShell.set_margin(window, Gtk4LayerShell.Edge.BOTTOM, 80)
        Gtk4LayerShell.set_namespace(window, "voice-recorder")

        window.set_default_size(380, 80)
        window.set_resizable(False)
        window.set_titlebar(Gtk.Box())

        # CSS with theme colors
        c = self.colors
        self.css_provider = Gtk.CssProvider()
        self.css_provider.load_from_string(f"""
            window {{
                background: transparent;
            }}
            .pill {{
                background-color: rgba({int(hex_to_rgb(c['surface'])[0]*255)}, {int(hex_to_rgb(c['surface'])[1]*255)}, {int(hex_to_rgb(c['surface'])[2]*255)}, 0.92);
                border-radius: 8px;
                padding: 8px 16px;
                font-family: monospace;
            }}
            .rec-dot {{
                color: #ff4444;
                font-size: 18px;
                font-family: monospace;
            }}
            .transcribing-dot {{
                color: {c['primary']};
                font-size: 18px;
                font-family: monospace;
            }}
            .time-label {{
                color: {c['on_surface_variant']};
                font-size: 13px;
                font-family: monospace;
            }}
        """)
        Gtk.StyleContext.add_provider_for_display(
            Gdk.Display.get_default(), self.css_provider,
            Gtk.STYLE_PROVIDER_PRIORITY_APPLICATION
        )

        hbox = Gtk.Box(orientation=Gtk.Orientation.HORIZONTAL, spacing=10)
        hbox.add_css_class("pill")

        self.rec_dot = Gtk.Label(label="\u25cf")
        self.rec_dot.add_css_class("rec-dot")
        self.rec_dot.set_valign(Gtk.Align.CENTER)
        hbox.append(self.rec_dot)

        self.drawing_area = Gtk.DrawingArea()
        self.drawing_area.set_hexpand(True)
        self.drawing_area.set_vexpand(True)
        self.drawing_area.set_draw_func(self.draw_waveform)
        hbox.append(self.drawing_area)

        self.label_time = Gtk.Label(label="0:00")
        self.label_time.add_css_class("time-label")
        self.label_time.set_valign(Gtk.Align.CENTER)
        hbox.append(self.label_time)

        window.set_child(hbox)

        # Escape key cancels recording/transcription
        key_controller = Gtk.EventControllerKey()
        key_controller.connect("key-pressed", self.on_key_pressed)
        window.add_controller(key_controller)

        window.present()


# --- Notification ---

def notify(message):
    """Send a desktop notification."""
    try:
        subprocess.Popen(
            ["notify-send", "-a", "Voice Recorder", "-t", "3000", "Voice-to-Text", message],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )
    except FileNotFoundError:
        pass


# --- App lifecycle ---

def on_activate(app, daemon):
    """GTK app activate callback — just hold the app open and write PID."""
    daemon.app = app
    app.hold()

    # Write PID file
    with open(PID_FILE, "w") as f:
        f.write(str(os.getpid()))


def main():
    GLib.set_prgname("voice-recorder")
    GLib.set_application_name("Voice Recorder")

    daemon = RecorderDaemon()

    # Register signal handlers via GLib (GTK-safe, runs on main thread)
    GLib.unix_signal_add(GLib.PRIORITY_HIGH, signal.SIGUSR1, daemon.on_sigusr1)
    GLib.unix_signal_add(GLib.PRIORITY_HIGH, signal.SIGTERM, daemon.on_sigterm)
    GLib.unix_signal_add(GLib.PRIORITY_HIGH, signal.SIGINT, daemon.on_sigterm)

    app = Gtk.Application(application_id="dev.dotfiles.voice-recorder")
    app.connect("activate", on_activate, daemon)

    try:
        app.run(None)
    finally:
        # Clean up on exit
        if daemon.stream is not None:
            daemon.stream.stop()
            daemon.stream.close()
        for f in (PID_FILE, WAV_FILE):
            try:
                os.unlink(f)
            except FileNotFoundError:
                pass


if __name__ == "__main__":
    main()
